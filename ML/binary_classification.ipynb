{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a4c1d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 09:37:28.965394: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 09:37:28.970479: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 09:37:29.034440: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 09:37:29.941695: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran the import statements.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# The following lines adjust the granularity of reporting.\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "# tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "print(\"Ran the import statements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b12569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
    "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")\n",
    "train_df = train_df.reindex(np.random.permutation(train_df.index)) # shuffle the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd8f20ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1.3</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8510</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16632</th>\n",
       "      <td>-1.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6626</th>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "357          1.3      -1.3                -1.2          0.2             0.1   \n",
       "8510         0.5      -0.7                 1.9         -0.1            -0.6   \n",
       "16632       -1.6       1.6                -0.4         -0.5            -0.3   \n",
       "9985        -0.1       0.6                -1.0         -0.1            -0.4   \n",
       "6626         0.6      -0.8                 1.0         -0.8            -0.8   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "357           0.2         0.2            0.3                -0.5  \n",
       "8510         -0.5        -0.6            5.2                 2.5  \n",
       "16632        -0.9        -0.7           -1.0                -0.8  \n",
       "9985         -0.3        -0.4            0.6                -0.9  \n",
       "6626         -0.6        -0.8           -1.3                -1.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Z-scores of each column in the training set and\n",
    "# write those Z-scores into a new pandas DataFrame named train_df_norm.\n",
    "train_df_mean = train_df.mean()\n",
    "train_df_std = train_df.std()\n",
    "train_df_norm = (train_df - train_df_mean)/train_df_std\n",
    "\n",
    "# Examine some of the values of the normalized training set. Notice that most\n",
    "# Z-scores fall between -2 and +2.\n",
    "train_df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ace77f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Z-scores of each column in the test set and\n",
    "# write those Z-scores into a new pandas DataFrame named test_df_norm.\n",
    "test_df_norm = (test_df - train_df_mean) / train_df_std\n",
    "\n",
    "# Note that we transform the test data with the values calculated from the training set,\n",
    "# as you should always transform your datasets with exactly the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3a19980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357     0.0\n",
       "8510    1.0\n",
       "16632   0.0\n",
       "9985    0.0\n",
       "6626    0.0\n",
       "         ..\n",
       "9420    1.0\n",
       "11772   0.0\n",
       "1569    0.0\n",
       "7629    1.0\n",
       "3760    0.0\n",
       "Name: median_house_value_is_high, Length: 8000, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 265000 # This is the 75th percentile for median house values.\n",
    "train_df_norm[\"median_house_value_is_high\"] = (train_df[\"median_house_value\"] > threshold).astype(float)\n",
    "test_df_norm[\"median_house_value_is_high\"] = (test_df[\"median_house_value\"] > threshold).astype(float)\n",
    "train_df_norm[\"median_house_value_is_high\"].head(8000)\n",
    "\n",
    "# Print out a few example cells from the beginning and\n",
    "# middle of the training set, just to make sure that\n",
    "# your code created only 0s and 1s in the newly created\n",
    "# median_house_value_is_high column\n",
    "train_df_norm[\"median_house_value_is_high\"].head(8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae87e7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357     0.0\n",
       "8510    1.0\n",
       "16632   0.0\n",
       "9985    0.0\n",
       "6626    0.0\n",
       "         ..\n",
       "9420    1.0\n",
       "11772   0.0\n",
       "1569    0.0\n",
       "7629    1.0\n",
       "3760    0.0\n",
       "Name: median_house_value_is_high, Length: 8000, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We arbitrarily set the threshold to 265,000, which is\n",
    "# the 75th percentile for median house values.  Every neighborhood\n",
    "# with a median house price above 265,000 will be labeled 1,\n",
    "# and all other neighborhoods will be labeled 0.\n",
    "threshold = 265000\n",
    "train_df_norm[\"median_house_value_is_high\"] = (train_df[\"median_house_value\"] > threshold).astype(float)\n",
    "test_df_norm[\"median_house_value_is_high\"] = (test_df[\"median_house_value\"] > threshold).astype(float)\n",
    "train_df_norm[\"median_house_value_is_high\"].head(8000)\n",
    "\n",
    "\n",
    "# Alternatively, instead of picking the threshold\n",
    "# based on raw house values, you can work with Z-scores.\n",
    "# For example, the following possible solution uses a Z-score\n",
    "# of +1.0 as the threshold, meaning that no more\n",
    "# than 16% of the values in median_house_value_is_high\n",
    "# will be labeled 1.\n",
    "\n",
    "# threshold_in_Z = 1.0\n",
    "# train_df_norm[\"median_house_value_is_high\"] = (train_df_norm[\"median_house_value\"] > threshold_in_Z).astype(float)\n",
    "# test_df_norm[\"median_house_value_is_high\"] = (test_df_norm[\"median_house_value\"] > threshold_in_Z).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f26bf499",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "# Features used to train the model on.\n",
    "  'median_income': tf.keras.Input(shape=(1,)),\n",
    "  'total_rooms': tf.keras.Input(shape=(1,))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5063bc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the create_model and train_model functions.\n"
     ]
    }
   ],
   "source": [
    "def create_model(my_inputs, my_learning_rate, METRICS):\n",
    "  # Use a Concatenate layer to concatenate the input layers into a single tensor.\n",
    "  # as input for the Dense layer. Ex: [input_1[0][0], input_2[0][0]]\n",
    "  concatenated_inputs = tf.keras.layers.Concatenate()(my_inputs.values())\n",
    "  dense = layers.Dense(units=1, name='dense_layer', activation=tf.sigmoid)\n",
    "  dense_output = dense(concatenated_inputs)\n",
    "  \"\"\"Create and compile a simple classification model.\"\"\"\n",
    "  my_outputs = {\n",
    "    'dense': dense_output,\n",
    "  }\n",
    "  model = tf.keras.Model(inputs=my_inputs, outputs=my_outputs)\n",
    "\n",
    "  # Call the compile method to construct the layers into a model that\n",
    "  # TensorFlow can execute.  Notice that we're using a different loss\n",
    "  # function for classification than for regression.\n",
    "  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=METRICS)\n",
    "  return model\n",
    "\n",
    "\n",
    "def train_model(model, dataset, epochs, label_name,\n",
    "                batch_size=None, shuffle=True):\n",
    "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "  # The x parameter of tf.keras.Model.fit can be a list of arrays, where\n",
    "  # each array contains the data for one feature.  Here, we're passing\n",
    "  # every column in the dataset. Note that the feature_layer will filter\n",
    "  # away most of those columns, leaving only the desired columns and their\n",
    "  # representations as features.\n",
    "  features = {name:np.array(value) for name, value in dataset.items()}\n",
    "  label = np.array(features.pop(label_name))\n",
    "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=shuffle)\n",
    "\n",
    "  # The list of epochs is stored separately from the rest of history.\n",
    "  epochs = history.epoch\n",
    "\n",
    "  # Isolate the classification metric for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  return epochs, hist\n",
    "\n",
    "print(\"Defined the create_model and train_model functions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3e5cba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the plot_curve function.\n"
     ]
    }
   ],
   "source": [
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"\n",
    "  # list_of_metrics should be one of the names shown in:\n",
    "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Value\")\n",
    "\n",
    "  for m in list_of_metrics:\n",
    "    x = hist[m]\n",
    "    plt.plot(epochs[1:], x[1:], label=m)\n",
    "\n",
    "  plt.legend()\n",
    "\n",
    "print(\"Defined the plot_curve function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e85129c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m METRICS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m            tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                            threshold\u001b[38;5;241m=\u001b[39mclassification_threshold),\n\u001b[1;32m     12\u001b[0m           ]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Establish the model's topography.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m my_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMETRICS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# To view a PNG of this model's layers, uncomment the call to\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# `tf.keras.utils.plot_model` below. After running this code cell, click\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# the file folder on the left, then the `my_classification_model.png` file.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# tf.keras.utils.plot_model(my_model, \"my_classification_model.png\")\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model on the training set.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m epochs, hist \u001b[38;5;241m=\u001b[39m train_model(my_model, train_df_norm, epochs,\n\u001b[1;32m     24\u001b[0m                            label_name, batch_size)\n",
      "Cell \u001b[0;32mIn[39], line 4\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(my_inputs, my_learning_rate, METRICS)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(my_inputs, my_learning_rate, METRICS):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;66;03m# Use a Concatenate layer to concatenate the input layers into a single tensor.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;66;03m# as input for the Dense layer. Ex: [input_1[0][0], input_2[0][0]]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m   concatenated_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   dense \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_layer\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39msigmoid)\n\u001b[1;32m      6\u001b[0m   dense_output \u001b[38;5;241m=\u001b[39m dense(concatenated_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/layers/merging/concatenate.py:43\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Used purely for shape validation.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_shape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m---> 43\u001b[0m         \u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m     44\u001b[0m     ):\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA `Concatenate` layer should be called on a list of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat least 1 input. Received: input_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         )\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m input_shape):\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "label_name = \"median_house_value_is_high\"\n",
    "classification_threshold = 0.35\n",
    "\n",
    "# Establish the metrics the model will measure.\n",
    "METRICS = [\n",
    "           tf.keras.metrics.BinaryAccuracy(name='accuracy',\n",
    "                                           threshold=classification_threshold),\n",
    "          ]\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(inputs, learning_rate, METRICS)\n",
    "\n",
    "# To view a PNG of this model's layers, uncomment the call to\n",
    "# `tf.keras.utils.plot_model` below. After running this code cell, click\n",
    "# the file folder on the left, then the `my_classification_model.png` file.\n",
    "# tf.keras.utils.plot_model(my_model, \"my_classification_model.png\")\n",
    "\n",
    "# Train the model on the training set.\n",
    "epochs, hist = train_model(my_model, train_df_norm, epochs,\n",
    "                           label_name, batch_size)\n",
    "\n",
    "# Plot a graph of the metric(s) vs. epochs.\n",
    "list_of_metrics_to_plot = ['accuracy']\n",
    "\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20652f60",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m features \u001b[38;5;241m=\u001b[39m {name:np\u001b[38;5;241m.\u001b[39marray(value) \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m test_df_norm\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      2\u001b[0m label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(features\u001b[38;5;241m.\u001b[39mpop(label_name))\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmy_model\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(x \u001b[38;5;241m=\u001b[39m features, y \u001b[38;5;241m=\u001b[39m label, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_model' is not defined"
     ]
    }
   ],
   "source": [
    "features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
    "label = np.array(features.pop(label_name))\n",
    "\n",
    "my_model.evaluate(x = features, y = label, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4fcb25e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dict_values([<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_2>, <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_3>]) (of type <class 'dict_values'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 20\u001b[0m\n\u001b[1;32m      9\u001b[0m METRICS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m       tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                       threshold\u001b[38;5;241m=\u001b[39mclassification_threshold),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m                               name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     17\u001b[0m ]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Establish the model's topography.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m my_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMETRICS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model on the training set.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m epochs, hist \u001b[38;5;241m=\u001b[39m train_model(my_model, train_df_norm, epochs,\n\u001b[1;32m     24\u001b[0m                            label_name, batch_size)\n",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(my_inputs, my_learning_rate, METRICS)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(my_inputs, my_learning_rate, METRICS):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;66;03m# Use a Concatenate layer to concatenate the input layers into a single tensor.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;66;03m# as input for the Dense layer. Ex: [input_1[0][0], input_2[0][0]]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m   concatenated_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   dense \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_layer\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39msigmoid)\n\u001b[1;32m      6\u001b[0m   dense_output \u001b[38;5;241m=\u001b[39m dense(concatenated_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/layers/layer.py:721\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(args):\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, KerasTensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_tensor(\n\u001b[1;32m    719\u001b[0m             arg\n\u001b[1;32m    720\u001b[0m         ):\n\u001b[0;32m--> 721\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    722\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly input tensors may be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional arguments. The following argument value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be passed as a keyword argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m             )\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# Caches info about `call()` signature, args, kwargs.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m call_spec \u001b[38;5;241m=\u001b[39m CallSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_signature, args, kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dict_values([<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_2>, <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_3>]) (of type <class 'dict_values'>)"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "classification_threshold = 0.35\n",
    "label_name = \"median_house_value_is_high\"\n",
    "\n",
    "# Modify the following definition of METRICS to generate\n",
    "# not only accuracy and precision, but also recall:\n",
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy',\n",
    "                                      threshold=classification_threshold),\n",
    "      tf.keras.metrics.Precision(thresholds=classification_threshold,\n",
    "                                 name='precision'\n",
    "                                 ),\n",
    "      tf.keras.metrics.Recall(thresholds=classification_threshold,\n",
    "                              name=\"recall\"),\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(inputs, learning_rate, METRICS)\n",
    "\n",
    "# Train the model on the training set.\n",
    "epochs, hist = train_model(my_model, train_df_norm, epochs,\n",
    "                           label_name, batch_size)\n",
    "\n",
    "# Plot metrics vs. epochs\n",
    "list_of_metrics_to_plot = ['accuracy', 'precision', 'recall']\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19750551",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dict_values([<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_2>, <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_3>]) (of type <class 'dict_values'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 20\u001b[0m\n\u001b[1;32m      9\u001b[0m METRICS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m       tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                       threshold\u001b[38;5;241m=\u001b[39mclassification_threshold),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m                               name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     17\u001b[0m ]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Establish the model's topography.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m my_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMETRICS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model on the training set.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m epochs, hist \u001b[38;5;241m=\u001b[39m train_model(my_model, train_df_norm, epochs,\n\u001b[1;32m     24\u001b[0m                            label_name, batch_size)\n",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(my_inputs, my_learning_rate, METRICS)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(my_inputs, my_learning_rate, METRICS):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;66;03m# Use a Concatenate layer to concatenate the input layers into a single tensor.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;66;03m# as input for the Dense layer. Ex: [input_1[0][0], input_2[0][0]]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m   concatenated_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   dense \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_layer\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39msigmoid)\n\u001b[1;32m      6\u001b[0m   dense_output \u001b[38;5;241m=\u001b[39m dense(concatenated_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/layers/layer.py:721\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(args):\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, KerasTensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_tensor(\n\u001b[1;32m    719\u001b[0m             arg\n\u001b[1;32m    720\u001b[0m         ):\n\u001b[0;32m--> 721\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    722\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly input tensors may be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional arguments. The following argument value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be passed as a keyword argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m             )\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# Caches info about `call()` signature, args, kwargs.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m call_spec \u001b[38;5;241m=\u001b[39m CallSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_signature, args, kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dict_values([<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_2>, <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_3>]) (of type <class 'dict_values'>)"
     ]
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "classification_threshold = 0.35\n",
    "label_name = \"median_house_value_is_high\"\n",
    "\n",
    "# Here is the updated definition of METRICS:\n",
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy',\n",
    "                                      threshold=classification_threshold),\n",
    "      tf.keras.metrics.Precision(thresholds=classification_threshold,\n",
    "                                 name='precision'\n",
    "                                 ),\n",
    "      tf.keras.metrics.Recall(thresholds=classification_threshold,\n",
    "                              name=\"recall\"),\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(inputs, learning_rate, METRICS)\n",
    "\n",
    "# Train the model on the training set.\n",
    "epochs, hist = train_model(my_model, train_df_norm, epochs,\n",
    "                           label_name, batch_size)\n",
    "\n",
    "# Plot metrics vs. epochs\n",
    "list_of_metrics_to_plot = ['accuracy', \"precision\", \"recall\"]\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
    "\n",
    "\n",
    "# The new graphs suggest that precision and recall are\n",
    "# somewhat in conflict. That is, improvements to one of\n",
    "# those metrics may hurt the other metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c664195",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dict_values([<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_2>, <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_3>]) (of type <class 'dict_values'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 20\u001b[0m\n\u001b[1;32m      9\u001b[0m METRICS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m       tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                       threshold\u001b[38;5;241m=\u001b[39mclassification_threshold),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m                               name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     17\u001b[0m ]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Establish the model's topography.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m my_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMETRICS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model on the training set.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m epochs, hist \u001b[38;5;241m=\u001b[39m train_model(my_model, train_df_norm, epochs,\n\u001b[1;32m     24\u001b[0m                            label_name, batch_size)\n",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(my_inputs, my_learning_rate, METRICS)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(my_inputs, my_learning_rate, METRICS):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;66;03m# Use a Concatenate layer to concatenate the input layers into a single tensor.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;66;03m# as input for the Dense layer. Ex: [input_1[0][0], input_2[0][0]]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m   concatenated_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   dense \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_layer\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39msigmoid)\n\u001b[1;32m      6\u001b[0m   dense_output \u001b[38;5;241m=\u001b[39m dense(concatenated_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/layers/layer.py:721\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(args):\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, KerasTensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_tensor(\n\u001b[1;32m    719\u001b[0m             arg\n\u001b[1;32m    720\u001b[0m         ):\n\u001b[0;32m--> 721\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    722\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly input tensors may be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional arguments. The following argument value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be passed as a keyword argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m             )\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# Caches info about `call()` signature, args, kwargs.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m call_spec \u001b[38;5;241m=\u001b[39m CallSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_signature, args, kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dict_values([<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_2>, <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_3>]) (of type <class 'dict_values'>)"
     ]
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "classification_threshold = 0.52\n",
    "label_name = \"median_house_value_is_high\"\n",
    "\n",
    "# Here is the updated definition of METRICS:\n",
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy',\n",
    "                                      threshold=classification_threshold),\n",
    "      tf.keras.metrics.Precision(thresholds=classification_threshold,\n",
    "                                 name='precision'\n",
    "                                 ),\n",
    "      tf.keras.metrics.Recall(thresholds=classification_threshold,\n",
    "                              name=\"recall\"),\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(inputs, learning_rate, METRICS)\n",
    "\n",
    "# Train the model on the training set.\n",
    "epochs, hist = train_model(my_model, train_df_norm, epochs,\n",
    "                           label_name, batch_size)\n",
    "\n",
    "# Plot metrics vs. epochs\n",
    "list_of_metrics_to_plot = ['accuracy', \"precision\", \"recall\"]\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
    "\n",
    "# A `classification_threshold` of slightly over 0.5\n",
    "# appears to produce the highest accuracy (about 83%).\n",
    "# Raising the `classification_threshold` to 0.9 drops\n",
    "# accuracy by about 5%.  Lowering the\n",
    "# `classification_threshold` to 0.3 drops accuracy by\n",
    "# about 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d07ff68",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dict_values([<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_2>, <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_3>]) (of type <class 'dict_values'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m METRICS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m       tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mAUC(num_thresholds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Establish the model's topography.\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m my_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMETRICS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model on the training set.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m epochs, hist \u001b[38;5;241m=\u001b[39m train_model(my_model, train_df_norm, epochs,\n\u001b[1;32m     20\u001b[0m                            label_name, batch_size)\n",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(my_inputs, my_learning_rate, METRICS)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(my_inputs, my_learning_rate, METRICS):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;66;03m# Use a Concatenate layer to concatenate the input layers into a single tensor.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;66;03m# as input for the Dense layer. Ex: [input_1[0][0], input_2[0][0]]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m   concatenated_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   dense \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_layer\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39msigmoid)\n\u001b[1;32m      6\u001b[0m   dense_output \u001b[38;5;241m=\u001b[39m dense(concatenated_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/layers/layer.py:721\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(args):\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, KerasTensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_tensor(\n\u001b[1;32m    719\u001b[0m             arg\n\u001b[1;32m    720\u001b[0m         ):\n\u001b[0;32m--> 721\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    722\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly input tensors may be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional arguments. The following argument value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be passed as a keyword argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m             )\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# Caches info about `call()` signature, args, kwargs.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m call_spec \u001b[38;5;241m=\u001b[39m CallSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_signature, args, kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: dict_values([<KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_2>, <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=keras_tensor_3>]) (of type <class 'dict_values'>)"
     ]
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "label_name = \"median_house_value_is_high\"\n",
    "\n",
    "# AUC is a reasonable \"summary\" metric for\n",
    "# classification models.\n",
    "# Here is the updated definition of METRICS to\n",
    "# measure AUC:\n",
    "METRICS = [\n",
    "      tf.keras.metrics.AUC(num_thresholds=100, name='auc'),\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(inputs, learning_rate, METRICS)\n",
    "\n",
    "# Train the model on the training set.\n",
    "epochs, hist = train_model(my_model, train_df_norm, epochs,\n",
    "                           label_name, batch_size)\n",
    "\n",
    "# Plot metrics vs. epochs\n",
    "list_of_metrics_to_plot = ['auc']\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c61266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
